{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d90a8a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://nb.recohut.com/jupyter/pytorch/2021/04/21/rec-algo-ncf-pytorch-pyy0715.html\n",
    "# https://colab.research.google.com/github/recohut/notebook/blob/master/_notebooks/2021-04-21-rec-algo-ncf-pytorch-pyy0715.ipynb#scrollTo=VT89-ZSZ9pMl\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b217672",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'seed_everything' from 'utils' (C:\\Users\\trlon\\PycharmProjects\\pythonProject\\recommendation\\pytorch\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hit, ndcg, metrics, seed_everything\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Generalized_Matrix_Factorization, Multi_Layer_Perceptron, NeuMF\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCF_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NCF_Data\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'seed_everything' from 'utils' (C:\\Users\\trlon\\PycharmProjects\\pythonProject\\recommendation\\pytorch\\utils.py)"
     ]
    }
   ],
   "source": [
    "from utils import hit, ndcg, metrics, seed_everything\n",
    "from model import Generalized_Matrix_Factorization, Multi_Layer_Perceptron, NeuMF\n",
    "from CF_data import NCF_Data\n",
    "from data_loader import Rating_Datset\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35abb455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--out'], dest='out', nargs=None, const=None, default=True, type=None, choices=None, help='save model or not', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--seed\", \n",
    "    type=int, \n",
    "    default=42, \n",
    "    help=\"Seed\")\n",
    "parser.add_argument(\"--lr\", \n",
    "\ttype=float, \n",
    "\tdefault=0.001, \n",
    "\thelp=\"learning rate\")\n",
    "parser.add_argument(\"--dropout\", \n",
    "\ttype=float,\n",
    "\tdefault=0.2,  \n",
    "\thelp=\"dropout rate\")\n",
    "parser.add_argument(\"--batch_size\", \n",
    "\ttype=int, \n",
    "\tdefault=256, \n",
    "\thelp=\"batch size for training\")\n",
    "parser.add_argument(\"--epochs\", \n",
    "\ttype=int,\n",
    "\tdefault=10,  \n",
    "\thelp=\"training epoches\")\n",
    "parser.add_argument(\"--top_k\", \n",
    "\ttype=int, \n",
    "\tdefault=10, \n",
    "\thelp=\"compute metrics@top_k\")\n",
    "parser.add_argument(\"--factor_num\", \n",
    "\ttype=int,\n",
    "\tdefault=32, \n",
    "\thelp=\"predictive factors numbers in the model\")\n",
    "parser.add_argument(\"--layers\",\n",
    "    nargs='+', \n",
    "    default=[64,32,16,8],\n",
    "    help=\"MLP layers. Note that the first layer is the concatenation of user \\\n",
    "    and item embeddings. So layers[0]/2 is the embedding size.\")\n",
    "parser.add_argument(\"--num_ng\", \n",
    "\ttype=int,\n",
    "\tdefault=4, \n",
    "\thelp=\"Number of negative samples for training set\")\n",
    "parser.add_argument(\"--num_ng_test\", \n",
    "\ttype=int,\n",
    "\tdefault=100, \n",
    "\thelp=\"Number of negative samples for test set\")\n",
    "parser.add_argument(\"--out\", \n",
    "\tdefault=True,\n",
    "\thelp=\"save model or not\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1627d6cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seed_everything' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# seed for Reproducibility\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mseed_everything\u001b[49m(args\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m ml_1m \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[0;32m     10\u001b[0m     DATA_PATH, \n\u001b[0;32m     11\u001b[0m     sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     12\u001b[0m     names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     13\u001b[0m     engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seed_everything' is not defined"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(\"\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# seed for Reproducibility\n",
    "seed_everything(args.seed)\n",
    "\n",
    "# load data\n",
    "ml_1m = pd.read_csv(\n",
    "    DATA_PATH, \n",
    "    sep=\"::\", \n",
    "    names = ['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "    engine='python')\n",
    "\n",
    "# set the num_users, items\n",
    "num_users = ml_1m['user_id'].nunique()+1\n",
    "num_items = ml_1m['item_id'].nunique()+1\n",
    "\n",
    "# construct the train and test datasets\n",
    "data = NCF_Data(args, ml_1m)\n",
    "train_loader = data.get_train_instance()\n",
    "test_loader = data.get_test_instance()\n",
    "\n",
    "# set model and loss, optimizer\n",
    "model = NeuMF(args, num_users, num_items)\n",
    "model = model.to(device)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# train, evaluation\n",
    "best_hr = 0\n",
    "for epoch in range(1, args.epochs+1):\n",
    "    model.train() # Enable dropout (if have).\n",
    "    start_time = time.time()\n",
    "\n",
    "    for user, item, label in train_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(user, item)\n",
    "        loss = loss_function(prediction, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar('loss/Train_loss', loss.item(), epoch)\n",
    "\n",
    "    model.eval()\n",
    "    HR, NDCG = metrics(model, test_loader, args.top_k, device)\n",
    "    writer.add_scalar('Perfomance/HR@10', HR, epoch)\n",
    "    writer.add_scalar('Perfomance/NDCG@10', NDCG, epoch)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" + \n",
    "            time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
    "    print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
    "\n",
    "    if HR > best_hr:\n",
    "        best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
    "        if args.out:\n",
    "            if not os.path.exists(MODEL_PATH):\n",
    "                os.mkdir(MODEL_PATH)\n",
    "            torch.save(model, \n",
    "                '{}{}.pth'.format(MODEL_PATH, MODEL))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7a5bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
