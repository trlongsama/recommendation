{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e12add3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from math import ceil\n",
    "from os import path, makedirs\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ffdb4",
   "metadata": {},
   "source": [
    "user ratings, user data, movie data; \n",
    "Processing data with nan filling and outlier removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5093e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BrukerID</th>\n",
       "      <th>FilmID</th>\n",
       "      <th>Rangering</th>\n",
       "      <th>Tidstempel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900187.000000</td>\n",
       "      <td>900187.000000</td>\n",
       "      <td>900187.000000</td>\n",
       "      <td>8.986950e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2991.864495</td>\n",
       "      <td>1989.675878</td>\n",
       "      <td>4.279477</td>\n",
       "      <td>9.722414e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1736.204837</td>\n",
       "      <td>1126.366532</td>\n",
       "      <td>1.971075</td>\n",
       "      <td>1.214672e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.567039e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1458.000000</td>\n",
       "      <td>1037.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.653029e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2967.000000</td>\n",
       "      <td>1959.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.729904e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4501.000000</td>\n",
       "      <td>2963.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.752202e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6040.000000</td>\n",
       "      <td>3952.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.046455e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BrukerID         FilmID      Rangering    Tidstempel\n",
       "count  900187.000000  900187.000000  900187.000000  8.986950e+05\n",
       "mean     2991.864495    1989.675878       4.279477  9.722414e+08\n",
       "std      1736.204837    1126.366532       1.971075  1.214672e+07\n",
       "min         0.000000       0.000000       1.000000  9.567039e+08\n",
       "25%      1458.000000    1037.000000       3.000000  9.653029e+08\n",
       "50%      2967.000000    1959.000000       4.000000  9.729904e+08\n",
       "75%      4501.000000    2963.000000       5.000000  9.752202e+08\n",
       "max      6040.000000    3952.000000      10.000000  1.046455e+09"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv('raw_data/rangering.dat', sep='::', header=0,\n",
    "                         names=['BrukerID', 'FilmID', 'Rangering', 'Tidstempel'],\n",
    "                         engine='python')\n",
    "\n",
    "ratings_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281afc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BrukerID         0\n",
      "FilmID           0\n",
      "Rangering        0\n",
      "Tidstempel    1492\n",
      "dtype: int64 \n",
      "\n",
      "There are 900187 rows in the dataset.\n",
      "Proportion of missing data for each column in %: \n",
      "BrukerID      0.00\n",
      "FilmID        0.00\n",
      "Rangering     0.00\n",
      "Tidstempel    0.17\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_vals = ratings_df.isnull().sum()\n",
    "print(missing_vals, '\\n')\n",
    "perc = round(missing_vals / ratings_df.shape[0] * 100, 2)\n",
    "print(f'There are {ratings_df.shape[0]} rows in the dataset.')\n",
    "print(f'Proportion of missing data for each column in %: \\n{perc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b183eb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_of_conversion 965109600.0\n",
      "Total number of missing values after imputing the avg timestamp for 1359 entries:  133 \n",
      "\n",
      "missing timestamp and high rating:  63\n",
      "Missing values after deleting the remaining entries with a rating < 6: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trlon\\AppData\\Local\\Temp\\ipykernel_24148\\3771604912.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ratings_df_cleaned = old_scaling.append(new_scaling, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "missing_df = ratings_df[ratings_df['Tidstempel'].isnull()]\n",
    "not_missing_df = ratings_df[ratings_df['Tidstempel'].notnull()]\n",
    "\n",
    "# Store the timestamp of the date of conversion (965088000) as a variable\n",
    "date = '01/08/2000 01:00:00'  # UTC +1\n",
    "date_of_conversion = time.mktime(datetime.datetime.strptime(date, \"%d/%m/%Y %H:%M:%S\").utctimetuple())\n",
    "print('date_of_conversion', date_of_conversion)  # 965088000\n",
    "\n",
    "old_scaling = not_missing_df[not_missing_df['Tidstempel'] < date_of_conversion]\n",
    "new_scaling = not_missing_df[not_missing_df['Tidstempel'] >= date_of_conversion]\n",
    "\n",
    "rated_before = old_scaling['BrukerID'].unique().tolist()\n",
    "rated_after = new_scaling['BrukerID'].unique().tolist()\n",
    "rated_before_and_after = []\n",
    "\n",
    "for user in rated_before:\n",
    "    if user in rated_after:\n",
    "        rated_before_and_after.append(user)\n",
    "# print('RATED BOTH:', len(rated_before_and_after))   # 383 user rated both before and after\n",
    "\n",
    "rated_only_before = sorted(list(set(rated_before).difference(rated_before_and_after)))\n",
    "rated_only_after = sorted(list(set(rated_after).difference(rated_before_and_after)))\n",
    "\n",
    "imputed = 0\n",
    "for row in missing_df.iterrows():\n",
    "    index = row[0]\n",
    "    user_id = int(row[1][0])\n",
    "\n",
    "    if user_id in rated_only_before:\n",
    "        avg_timestamp = old_scaling.loc[old_scaling['BrukerID'] == user_id, 'Tidstempel'].mean()\n",
    "        ratings_df.loc[index, 'Tidstempel'] = avg_timestamp\n",
    "        imputed += 1\n",
    "\n",
    "    elif user_id in rated_only_after:\n",
    "        avg_timestamp = new_scaling.loc[new_scaling['BrukerID'] == user_id, 'Tidstempel'].mean()\n",
    "        ratings_df.loc[index, 'Tidstempel'] = avg_timestamp\n",
    "        imputed += 1\n",
    "\n",
    "print(f'Total number of missing values after imputing the avg timestamp for {imputed} entries: ',\n",
    "      ratings_df.isnull().sum().sum(), '\\n')\n",
    "\n",
    "# Now we can determine if there are any of the 131 remaining ratings with a rating > 5:\n",
    "missing_df = ratings_df[ratings_df['Tidstempel'].isnull()]\n",
    "missing_and_high_rating = missing_df.loc[missing_df['Rangering'] > 5]\n",
    "print('missing timestamp and high rating: ', len(missing_and_high_rating))\n",
    "\n",
    "# Imputing the average timestamp for old ratings for the 63 entries with missing timestamp and a rating > 5\n",
    "for row in missing_and_high_rating.iterrows():\n",
    "    index = row[0]\n",
    "    user_id = int(row[1][0])\n",
    "    avg_timestamp = old_scaling.loc[:, 'Tidstempel'].mean()\n",
    "    ratings_df.loc[index, 'Tidstempel'] = avg_timestamp\n",
    "\n",
    "# Dropping remaining 68 entries with missing timestamp values and a rating < 6\n",
    "ratings_df.dropna(how='any', inplace=True)\n",
    "\n",
    "print(f'Missing values after deleting the remaining entries with a rating < 6: {ratings_df.isnull().sum().sum()}')\n",
    "\n",
    "\n",
    "# Converting the scale for ratings prior to 01.08.2000 from 1-10 to 1-5.\n",
    "# First, converting the timestamp from float to int\n",
    "ratings_df['Tidstempel'] = ratings_df['Tidstempel'].astype(int)\n",
    "\n",
    "# Splitting the dataset into pre and post conversion date again,\n",
    "# this time converting the old ratings to the new scale.\n",
    "old_scaling = ratings_df[ratings_df['Tidstempel'] < date_of_conversion]\n",
    "new_scaling = ratings_df[ratings_df['Tidstempel'] >= date_of_conversion]\n",
    "\n",
    "pd.reset_option('mode.chained_assignment')  # THE CODE BELOW CAUSES SETTINGWITHCOPYWARNING, DUE TO CHAINED ASSIGNMENT\n",
    "with pd.option_context('mode.chained_assignment', None):\n",
    "    # Converting the scale for ratings from 1-10 to 1-5.\n",
    "    # Replacing the values from integers to strings, so that I can use regex on them\n",
    "    old_scaling['Rangering'].replace(to_replace=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                     value=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'], inplace=True)\n",
    "\n",
    "    # Using regex to find values and then replacing them with corresponding values on the new scale.\n",
    "    # 1's and 2's = 1, 3's and 4's = 2, etc.\n",
    "    old_scaling['Rangering'].replace(regex=True, to_replace=['1\\b|2', '3|4', '5|6', '7|8', '9|10'],\n",
    "                                     value=[1, 2, 3, 4, 5], inplace=True)\n",
    "\n",
    "    # Appending the new ratings to the old\n",
    "    ratings_df_cleaned = old_scaling.append(new_scaling, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6809c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new folder for the cleaned data, unless it already exists\n",
    "if path.exists('cleaned_data'):\n",
    "    print('cleaned_data folder already exists')\n",
    "else:\n",
    "    makedirs('cleaned_data')\n",
    "\n",
    "# Writing the dataframe to a .csv file and storing it in cleaned data\n",
    "ratings_df_cleaned.to_csv('cleaned_data/rangering.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b78da",
   "metadata": {},
   "source": [
    "bruker.json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00982d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BrukerID</th>\n",
       "      <th>Kjonn</th>\n",
       "      <th>Alder</th>\n",
       "      <th>Jobb</th>\n",
       "      <th>Postkode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>55405-2546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>M</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>70806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>45701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BrukerID Kjonn  Alder  Jobb    Postkode\n",
       "0         0  None   45.0   6.0       92103\n",
       "1         1     M   50.0  16.0  55405-2546\n",
       "2         2     M   18.0  20.0       44089\n",
       "3         3     M    NaN   1.0       33304\n",
       "4         4     M   35.0   6.0       48105\n",
       "5         5     M   25.0  20.0        None\n",
       "6         6     M   50.0  14.0        None\n",
       "7         7     F   25.0   0.0        None\n",
       "8         8     M   25.0   4.0       70806\n",
       "9         9     M   25.0  19.0       45701"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset as DataFrame object, setting column labels\n",
    "users_df = pd.read_json('raw_data/bruker.json', orient='split')\n",
    "\n",
    "users_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efaacd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6040 rows in the dataset.\n",
      "Proportion of missing data for each column in %: \n",
      "BrukerID     0.00\n",
      "Kjonn        5.02\n",
      "Alder       16.46\n",
      "Jobb         9.82\n",
      "Postkode     7.47\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_vals = users_df.isnull().sum()\n",
    "perc = round(missing_vals / users_df.shape[0] * 100, 2)\n",
    "print(f'There are {users_df.shape[0]} rows in the dataset.')\n",
    "print(f'Proportion of missing data for each column in %: \\n{perc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b59a0768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BrukerID</th>\n",
       "      <th>Kjonn</th>\n",
       "      <th>Alder</th>\n",
       "      <th>Jobb</th>\n",
       "      <th>Postkode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>55405-2546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>44089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BrukerID Kjonn  Alder  Jobb    Postkode\n",
       "0         0  None   45.0   6.0       92103\n",
       "1         1     M   50.0  16.0  55405-2546\n",
       "2         2     M   18.0  20.0       44089\n",
       "3         3     M    NaN   1.0       33304\n",
       "4         4     M   35.0   6.0       48105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NA values in 'Jobb' column with 0, indicating 'other/unspecified'\n",
    "users_df['Jobb'].fillna(0, inplace=True)\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189869d",
   "metadata": {},
   "source": [
    "Imputation for missing data in users dataset with KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e08940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING DATA FOR KNN IMPUTER\n",
    "# 1) Normalizing gender categories from 'M' and 'F' to 1 and 0\n",
    "users_df.replace(to_replace=['M', 'F'], value=[1, 0], inplace=True)\n",
    "\n",
    "# 2) Adding the postal codes without the hyphen and the following integers with Sector, Blocks, and Side of Street\n",
    "#    from postal codes to a new column, which can be used for KNN predictions\n",
    "users_df['Postkode_5'] = users_df.Postkode.str[:3]\n",
    "\n",
    "# 3) Removing features that are unecessary/unhelpful for KNN predictions\n",
    "df = users_df.drop(['Postkode', 'BrukerID'], axis=1)\n",
    "\n",
    "# 4) Scaling the numeric variables to have values between 0 and 1.\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b879e9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kjonn         0\n",
      "Alder         0\n",
      "Jobb          0\n",
      "Postkode_5    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Perform KNN imputation on missing values\n",
    "imputer = KNNImputer(n_neighbors=5, )\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e37801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    BrukerID Kjonn  Alder  Jobb    Postkode\n",
      "0          0     F     45     6       92103\n",
      "1          1     M     50    16  55405-2546\n",
      "2          2     M     18    20       44089\n",
      "3          3     M     35     1       33304\n",
      "4          4     M     35     6       48105\n",
      "5          5     M     25    20         470\n",
      "6          6     M     50    14         379\n",
      "7          7     F     25     0         264\n",
      "8          8     M     25     4       70806\n",
      "9          9     M     25    19       45701\n",
      "10        10     F     18     1       95864\n",
      "11        11     M     35     1         478\n",
      "12        12     M     45     0       10543\n",
      "13        13     M     50     7       34243\n",
      "14        14     M     25     4       53140\n",
      "15        15     F     18     4       60625\n",
      "16        16     M     25    17       03570\n",
      "17        17     M     35     7       30117\n",
      "18        18     M     50     1       01096\n",
      "19        19     M     25    15       02143\n"
     ]
    }
   ],
   "source": [
    "# Reverting scaling, so that the data is readable\n",
    "df = pd.DataFrame(scaler.inverse_transform(df), columns=df.columns)\n",
    "\n",
    "# Adding 'BrukerID' and complete postal codes back again\n",
    "df[['BrukerID', 'Postkode']] = users_df[['BrukerID', 'Postkode']]\n",
    "\n",
    "# Renaming the new dataframe in order to replace the old one, while reordering the columns simultaenously\n",
    "users_df = df[['BrukerID', 'Kjonn', 'Alder', 'Jobb', 'Postkode', 'Postkode_5']]\n",
    "\n",
    "# Iterating over the dataframe, fixing stuff as I go\n",
    "for row in users_df.iterrows():\n",
    "    index = row[0]\n",
    "    gender = row[1][1]\n",
    "    age = row[1][2]\n",
    "    job = row[1][3]\n",
    "    postcode = str(row[1][4])\n",
    "    postcode_5 = row[1][5]\n",
    "\n",
    "    # Rounding imputed postal code values from float to whole int. Then convert to string\n",
    "    users_df.iloc[index, 5] = str(int(round(postcode_5)))\n",
    "\n",
    "    # Inserting the full postal codes back into the new postal code column.\n",
    "    # This leaves the imputed postcode values as three-digit postal codes,\n",
    "    # which means that they can't be used to send anything by mail. However, they can be used for\n",
    "    # user-based filtering or profiling, as a postal code with three digits indicates the region/city\n",
    "    # in which the user most likely would reside in.\n",
    "    if len(postcode) >= 5:\n",
    "        users_df.iloc[index, 5] = postcode\n",
    "\n",
    "    # Rounding/normalizing gender values from float to either 'M' if >=0.5 or else 'F'\n",
    "    if gender >= 0.5:\n",
    "        users_df.iloc[index, 1] = 'M'\n",
    "    else:\n",
    "        users_df.iloc[index, 1] = 'F'\n",
    "\n",
    "    # Rounding age values to closest age interval according to the README\n",
    "    if age < 18:\n",
    "        users_df.iloc[index, 2] = 1\n",
    "    elif 18 <= age < 25:\n",
    "        users_df.iloc[index, 2] = 18\n",
    "    elif 25 <= age < 35:\n",
    "        users_df.iloc[index, 2] = 25\n",
    "    elif 35 <= age < 45:\n",
    "        users_df.iloc[index, 2] = 35\n",
    "    elif 45 <= age < 50:\n",
    "        users_df.iloc[index, 2] = 45\n",
    "    elif 50 <= age < 56:\n",
    "        users_df.iloc[index, 2] = 50\n",
    "    else:\n",
    "        users_df.iloc[index, 2] = 56\n",
    "\n",
    "# Changing features that are dtype float (Kjonn, Alder, Jobb) back into dtype int\n",
    "users_df[['Alder', 'Jobb']] = users_df[['Alder', 'Jobb']].astype(dtype=int)\n",
    "\n",
    "# Remove the old postal code column, rename the new one\n",
    "users_df['Postkode'] = users_df['Postkode_5']\n",
    "users_df.drop('Postkode_5', axis=1, inplace=True)\n",
    "\n",
    "print(users_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44015ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6040 rows in the dataset.\n",
      "Proportion of missing data for each column in %: \n",
      "BrukerID    0.0\n",
      "Kjonn       0.0\n",
      "Alder       0.0\n",
      "Jobb        0.0\n",
      "Postkode    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values again\n",
    "missing_vals = users_df.isnull().sum()\n",
    "perc = round(missing_vals / users_df.shape[0] * 100, 2)\n",
    "print(f'There are {users_df.shape[0]} rows in the dataset.')\n",
    "print(f'Proportion of missing data for each column in %: \\n{perc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e770be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the dataframe to a .csv file and storing it in cleaned data folder\n",
    "users_df.to_csv('cleaned_data/bruker.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e8045",
   "metadata": {},
   "source": [
    "film data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26331637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3883 movies in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Load data from Excel file to DataFrame object\n",
    "excel = pd.ExcelFile('raw_data/film.xlsx')\n",
    "movies_df = excel.parse(sheet_name='film', index_col=None)\n",
    "movies_df.drop(labels=['Unnamed: 0'], axis=1, inplace=True)\n",
    "print(f'There are {movies_df.count()[0]} movies in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "194c1eae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CONVERTING GENRE FEATURE FROM ONE NOMINAL COLUMN TO 18 DISCRETE COLUMNS\n",
    "# 1) Adding labels for the 18 different genres with 0 as default value\n",
    "genres = [\"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\",\n",
    "          \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n",
    "for genre in genres:\n",
    "    movies_df.loc[:,genre] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b5b7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Looping over the nominal genre column, and setting the discrete columns accordingly\n",
    "for row in movies_df.iterrows():\n",
    "    index = row[0]\n",
    "    genre_data = row[1][2]\n",
    "\n",
    "    genres = movies_df.columns.values.tolist()\n",
    "    genres.remove('FilmID')\n",
    "    genres.remove('Tittel')\n",
    "    genres.remove('Sjanger')\n",
    "\n",
    "    for genre in genres:\n",
    "        if genre in genre_data:\n",
    "            movies_df.loc[index, genre] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f876dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove genre nominal column, as it is no longer needed\n",
    "movies_df.drop(labels=['Sjanger'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fe0fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the dataframe to a .csv file and storing it in cleaned data folder\n",
    "movies_df.to_csv('cleaned_data/film.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9667624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
